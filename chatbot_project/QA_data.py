import os
import json
import re
from dotenv import load_dotenv
from tqdm import tqdm
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”© (.env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì • í•„ìš”)
load_dotenv()

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(
    temperature=0.3,
    model="gpt-4o-mini"  # í•„ìš” ì‹œ gpt-4ë¡œ ë³€ê²½ ê°€ëŠ¥
)

# í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
def build_prompt(document_title: str, content: str) -> str:
    return (
        f"ë„ˆëŠ” ìŠ¤ë§ˆíŠ¸í•œ ë¬¸ì„œ ë…í•´ ì±—ë´‡ì´ë‹¤.\n\n"
        f"ì•„ë˜ëŠ” '{document_title}'ì´ë¼ëŠ” ì œí’ˆ ë§¤ë‰´ì–¼ì˜ ì¼ë¶€ì´ë‹¤.\n"
        f"ì´ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì§ˆë¬¸í•  ë§Œí•œ ì§ˆë¬¸ê³¼ ì´ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ í•˜ë‚˜ë§Œ ìƒì„±í•˜ë¼.\n\n"
        f"ì¤‘ìš” ì¡°ê±´:\n"
        f"- ìƒì„±ëœ Q&AëŠ” ë°˜ë“œì‹œ ì£¼ì–´ì§„ ì •ë³´ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•œë‹¤.\n"
        f"- ì§ˆë¬¸ê³¼ ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•œë‹¤.\n"
        f"- ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì•¼ í•œë‹¤.\n"
        f"- ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ë¶€ì¡±í•˜ê±°ë‚˜ ì§ˆë¬¸í•  ë§Œí•œ ê²ƒì´ ì—†ë‹¤ë©´, ë¹ˆ ë¦¬ìŠ¤íŠ¸([])ë§Œ ë°˜í™˜í•˜ë¼.\n\n"
        f"ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬:\n"
        f"1. 'ë¬¸ì œ í•´ê²°' - ì œí’ˆ ì‚¬ìš© ì¤‘ ìƒê¸°ëŠ” ê³ ì¥, ì˜¤ë¥˜, ë¶ˆí¸ì„ í•´ê²°í•˜ëŠ” ì§ˆë¬¸\n"
        f"2. 'ì œí’ˆ ì‚¬ìš©ë²• ì´í•´' - ê¸°ëŠ¥, ì„¤ì •, ì ˆì°¨, ì¡°ì‘ë²• ë“±ì„ ë¬»ëŠ” ì§ˆë¬¸\n"
        f"3. 'ì •ë³´ íƒìƒ‰ ë° ì„ íƒ' - ì œí’ˆ ìŠ¤í™, êµ¬ì„±í’ˆ, ë¹„êµ, êµ¬ë§¤ ê´€ë ¨ ì •ë³´ íƒìƒ‰ ì§ˆë¬¸\n\n"
        f"JSON í˜•ì‹ ì˜ˆì‹œ:\n"
        f"[{{\n"
        f"  \"question\": str,\n"
        f"  \"answer\": str,\n"
        f"  \"category\": str,\n"
        f"  \"product\": \"{document_title}\"\n"
        f"}}]\n\n"
        f"ë¬¸ì„œ ë‚´ìš©:\n"
        f"{content}"
    )

# LLM í˜¸ì¶œ ë° ê²°ê³¼ íŒŒì‹±
def generate_qa_pair(text: str, document_title: str) -> dict | None:
    prompt = build_prompt(document_title=document_title, content=text)
    try:
        response = llm.invoke(prompt)
        output = response.content.strip()

        if not output or output == "[]":
            return None

        # ì½”ë“œ ë¸”ë¡ ì œê±° (```json í¬í•¨ ê°€ëŠ¥ì„±)
        cleaned = re.sub(r"```json|```", "", output).strip()

        parsed = json.loads(cleaned)
        if isinstance(parsed, list) and len(parsed) > 0:
            return parsed[0]
        else:
            return None

    except Exception as e:
        print("ğŸ”¥ LLM ì˜¤ë¥˜ ë°œìƒ:", e)
        return None

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    input_path = "chunked_data.jsonl"
    output_path = "qa_dataset.jsonl"
    document_title = "ì‚¼ì„±"  # ì‹¤ì œ ì œí’ˆ ì´ë¦„ ì…ë ¥

    with open(input_path, "r", encoding="utf-8") as infile, open(output_path, "w", encoding="utf-8") as outfile:
        for idx, line in enumerate(tqdm(infile, desc="Generating QA pairs", unit="chunk")):
            data = json.loads(line)
            chunk = data.get("chunk", "").strip()
            document_title = data.get("title", "ë¯¸í™•ì¸ ì œí’ˆ")
            
            if len(chunk) < 100:
                continue

            qa = generate_qa_pair(chunk, document_title)
            if qa:
                json.dump(qa, outfile, ensure_ascii=False)
                outfile.write("\n")
